{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "def6c2b16be03b8590d636aa576bdaff4206d1ae9e8a5ace4be932c0f896e5bb"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Test Environment for Generative AI classroom labs\n\nThis lab provides a test environment for the codes generated using the Generative AI classroom.\n\nFollow the instructions below to set up this environment for further use.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Setup\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Install required libraries\n\nIn case of a requirement of installing certain python libraries for use in your task, you may do so as shown below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%pip install seaborn\nimport piplite\n\nawait piplite.install(['nbformat', 'plotly'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": "### Dataset URL from the GenAI lab\nUse the URL provided in the GenAI lab in the cell below. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod1.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": "### Downloading the dataset\n\nExecute the following code to download the dataset in to the interface.\n\n> Please note that this step is essential in JupyterLite. If you are using a downloaded version of this notebook and running it on JupyterLabs, then you can skip this step and directly use the URL in pandas.read_csv() function to read the dataset as a dataframe\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())\n\npath = URL\n\nawait download(path, \"dataset.csv\")\nfile_name  = \"dataset.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": "---\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Test Environment\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#AI instructions for the type of code to generate\n\n#“Generate plan basic python code without using definition or exceptions or if else statements. Response should be concise.”",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": "# Keep appending the code generated to this cell, or add more cells below this to execute in parts\n#Write a Python code that can perform the following tasks:\n#Read the CSV file, located on a given file path, into a Pandas data frame, assuming that the first rows of the file are the headers for the data.\n\nimport pandas as pd\n\n# Path to the CSV file (update this to your actual file path)\nfile_path = file_name\n\n# Read the CSV into a DataFrame, treating the first row as the header\ndf = pd.read_csv(file_path, header=0)\n\ndf.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Unnamed: 0 Manufacturer  Category     Screen  GPU  OS  CPU_core  \\\n0           0         Acer         4  IPS Panel    2   1         5   \n1           1         Dell         3    Full HD    1   1         3   \n2           2         Dell         3    Full HD    1   1         7   \n3           3         Dell         4  IPS Panel    2   1         5   \n4           4           HP         4    Full HD    2   1         7   \n\n   Screen_Size_cm  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_kg  Price  \n0          35.560            1.6       8             256       1.60    978  \n1          39.624            2.0       4             256       2.20    634  \n2          39.624            2.7       8             256       2.20    946  \n3          33.782            1.6       8             128       1.22   1244  \n4          39.624            1.8       8             256       1.91    837  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Manufacturer</th>\n      <th>Category</th>\n      <th>Screen</th>\n      <th>GPU</th>\n      <th>OS</th>\n      <th>CPU_core</th>\n      <th>Screen_Size_cm</th>\n      <th>CPU_frequency</th>\n      <th>RAM_GB</th>\n      <th>Storage_GB_SSD</th>\n      <th>Weight_kg</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Acer</td>\n      <td>4</td>\n      <td>IPS Panel</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>35.560</td>\n      <td>1.6</td>\n      <td>8</td>\n      <td>256</td>\n      <td>1.60</td>\n      <td>978</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Dell</td>\n      <td>3</td>\n      <td>Full HD</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>39.624</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>256</td>\n      <td>2.20</td>\n      <td>634</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Dell</td>\n      <td>3</td>\n      <td>Full HD</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>39.624</td>\n      <td>2.7</td>\n      <td>8</td>\n      <td>256</td>\n      <td>2.20</td>\n      <td>946</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Dell</td>\n      <td>4</td>\n      <td>IPS Panel</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>33.782</td>\n      <td>1.6</td>\n      <td>8</td>\n      <td>128</td>\n      <td>1.22</td>\n      <td>1244</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>HP</td>\n      <td>4</td>\n      <td>Full HD</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>39.624</td>\n      <td>1.8</td>\n      <td>8</td>\n      <td>256</td>\n      <td>1.91</td>\n      <td>837</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code that identifies the columns with missing values in a pandas data frame and gives missing value counts per column.\n\n# Compute missing value counts per column\nmissing_counts = df.isnull().sum()\n\n# Identify columns with at least one missing value\ncolumns_with_missing = missing_counts[missing_counts > 0].index.tolist()\n\n# Output results\nprint(\"Missing value counts per column:\")\nprint(missing_counts)\n\nprint(\"Columns with missing values:\")\nprint(columns_with_missing)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Missing value counts per column:\nUnnamed: 0        0\nManufacturer      0\nCategory          0\nScreen            0\nGPU               0\nOS                0\nCPU_core          0\nScreen_Size_cm    4\nCPU_frequency     0\nRAM_GB            0\nStorage_GB_SSD    0\nWeight_kg         5\nPrice             0\ndtype: int64\nColumns with missing values:\n['Screen_Size_cm', 'Weight_kg']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code to replace the missing values in a pandas data frame, per the following guidelines.\n#1. For a categorical attribute \"Screen_Size_cm\", replace the missing values with the most frequent value in the column.\n#2. For a continuous value attribute \"Weight_kg\", replace the missing values with the mean value of the entries in the column.\n\n# 1) Replace missing Screen_Size_cm values with the most frequent value (mode)\nmost_freq_screen = df['Screen_Size_cm'].mode().iloc[0]\n\n# 2) Replace missing Weight_kg values with the mean of the column\nmean_weight = df['Weight_kg'].mean()\n\n# Apply replacements for both columns in a single operation\ndf.fillna({'Screen_Size_cm': most_freq_screen, 'Weight_kg': mean_weight}, inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code snippet to change the data type of the attributes \"Screen_Size_cm\" and \"Weight_kg\" of a data frame to float.\n\n# Convert the specified columns to float (coerce non-numeric values to NaN)\ndf['Screen_Size_cm'] = pd.to_numeric(df['Screen_Size_cm'], errors='coerce')\ndf['Weight_kg'] = pd.to_numeric(df['Weight_kg'], errors='coerce')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code to modify the contents under the following attributes of the data frame as required.\n#1. Data under 'Screen_Size_cm' is assumed to be in centimeters. Convert this data into inches. Modify the name of the attribute to 'Screen_Size_inch'.\n#2. Data under 'Weight_kg' is assumed to be in kilograms. Convert this data into pounds. Modify the name of the attribute to 'Weight_pounds'.\n\n# 1) Convert Screen_Size_cm (cm) to Screen_Size_inch (inches) and drop the old column\ndf['Screen_Size_inch'] = df['Screen_Size_cm'] / 2.54\ndf.drop(columns=['Screen_Size_cm'], inplace=True)\n\n# 2) Convert Weight_kg (kg) to Weight_pounds (lb) and drop the old column\ndf['Weight_pounds'] = df['Weight_kg'] * 2.2046226218\ndf.drop(columns=['Weight_kg'], inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code to normalize the content under the attribute \"CPU_frequency\" in a data frame df concerning its maximum value. Make changes to the original data, and do not create a new attribute.\n\n# Normalize the 'CPU_frequency' column in place by its maximum value\n# Assumes 'df' is a pre-loaded DataFrame containing a numeric 'CPU_frequency' column\nmax_val = df['CPU_frequency'].max()\ndf['CPU_frequency'] = df['CPU_frequency'].div(max_val)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 31
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code to perform the following tasks.\n#1. Convert a data frame df attribute \"Screen\", into indicator variables, saved as df1, with the naming convention \"Screen_<unique value of the attribute>\".\n#2. Append df1 into the original data frame df.\n#3. Drop the original attribute from the data frame df.\n\n# One-hot encode the 'Screen' column into separate indicator columns\n# The resulting df1 will have column names like 'Screen_<category>'\ndf1 = pd.get_dummies(df['Screen'], prefix='Screen')\n\n# Append the new indicator columns to the original dataframe\ndf = pd.concat([df, df1], axis=1)\n\n# Drop the original 'Screen' column\ndf.drop(columns=['Screen'], inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 32
    },
    {
      "cell_type": "code",
      "source": "#Convert the values under a df column named Price from USD to Euros\n\n# Convert the 'Price' column from USD to EUR in place\n# Update the exchange rate as needed\nUSD_TO_EUR = 0.92  # example rate: 1 USD = 0.92 EUR\n\n# In-place conversion\ndf['Price'] = df['Price'] * USD_TO_EUR",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code to normalize the content under the attribute \"CPU_frequency\" in a data frame df concerning its minimum and maximum value. Make changes to the original data, and do not create a new attribute.\n\nimport numpy as np\n\n# In-place min-max normalization of the 'CPU_frequency' column\nmin_val = df['CPU_frequency'].min()\nmax_val = df['CPU_frequency'].max()\nrange_val = max_val - min_val\n# Use a safe denominator: 1 when range is 0 to avoid division by zero; this retains 0s when all values are identical\ndf['CPU_frequency'] = (df['CPU_frequency'] - min_val) / np.where(range_val != 0, range_val, 1)\n\ndf.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Unnamed: 0 Manufacturer  Category  GPU  OS  CPU_core  CPU_frequency  \\\n0           0         Acer         4    2   1         5       0.235294   \n1           1         Dell         3    1   1         3       0.470588   \n2           2         Dell         3    1   1         7       0.882353   \n3           3         Dell         4    2   1         5       0.235294   \n4           4           HP         4    2   1         7       0.352941   \n\n   RAM_GB  Storage_GB_SSD    Price  Screen_Size_inch  Weight_pounds  \\\n0       8             256   899.76              14.0       3.527396   \n1       4             256   583.28              15.6       4.850170   \n2       8             256   870.32              15.6       4.850170   \n3       8             128  1144.48              13.3       2.689640   \n4       8             256   770.04              15.6       4.210829   \n\n   Screen_Full HD  Screen_IPS Panel  \n0           False              True  \n1            True             False  \n2            True             False  \n3           False              True  \n4            True             False  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Manufacturer</th>\n      <th>Category</th>\n      <th>GPU</th>\n      <th>OS</th>\n      <th>CPU_core</th>\n      <th>CPU_frequency</th>\n      <th>RAM_GB</th>\n      <th>Storage_GB_SSD</th>\n      <th>Price</th>\n      <th>Screen_Size_inch</th>\n      <th>Weight_pounds</th>\n      <th>Screen_Full HD</th>\n      <th>Screen_IPS Panel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Acer</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.235294</td>\n      <td>8</td>\n      <td>256</td>\n      <td>899.76</td>\n      <td>14.0</td>\n      <td>3.527396</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Dell</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.470588</td>\n      <td>4</td>\n      <td>256</td>\n      <td>583.28</td>\n      <td>15.6</td>\n      <td>4.850170</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Dell</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.882353</td>\n      <td>8</td>\n      <td>256</td>\n      <td>870.32</td>\n      <td>15.6</td>\n      <td>4.850170</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Dell</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.235294</td>\n      <td>8</td>\n      <td>128</td>\n      <td>1144.48</td>\n      <td>13.3</td>\n      <td>2.689640</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>HP</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.352941</td>\n      <td>8</td>\n      <td>256</td>\n      <td>770.04</td>\n      <td>15.6</td>\n      <td>4.210829</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34
    },
    {
      "cell_type": "markdown",
      "source": "## Lab on Using Generative AI for Data Insights ##",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Write a python code to perform the following actions.\n#1. Import a data set from a CSV file, The headers for the data set must be in the first row of the CSV file.\n#2. Generate the statistical description of all the features used in the data set. Include \"object\" data types as well.\n\nimport pandas as pd\n\n# Path to the input CSV file. Assumes the first row contains headers.\ncsv_path = 'dataset.csv'\n\n# Load the dataset; pandas automatically uses the first row as header by default.\ndf = pd.read_csv(csv_path)\n\n# Generate a statistical description for all features, including object types.\n# include='all' yields numeric statistics for numeric columns and frequency/unique counts for object types.\ndescription = df.describe(include='all')\n\n# Output the description to stdout. Converts non-numeric values into readable summary.\nprint(description)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "        Unnamed: 0 Manufacturer    Category   Screen         GPU          OS  \\\ncount   238.000000          238  238.000000      238  238.000000  238.000000   \nunique         NaN           11         NaN        2         NaN         NaN   \ntop            NaN         Dell         NaN  Full HD         NaN         NaN   \nfreq           NaN           71         NaN      161         NaN         NaN   \nmean    118.500000          NaN    3.205882      NaN    2.151261    1.058824   \nstd      68.848868          NaN    0.776533      NaN    0.638282    0.235790   \nmin       0.000000          NaN    1.000000      NaN    1.000000    1.000000   \n25%      59.250000          NaN    3.000000      NaN    2.000000    1.000000   \n50%     118.500000          NaN    3.000000      NaN    2.000000    1.000000   \n75%     177.750000          NaN    4.000000      NaN    3.000000    1.000000   \nmax     237.000000          NaN    5.000000      NaN    3.000000    2.000000   \n\n          CPU_core  Screen_Size_cm  CPU_frequency      RAM_GB  Storage_GB_SSD  \\\ncount   238.000000      234.000000     238.000000  238.000000      238.000000   \nunique         NaN             NaN            NaN         NaN             NaN   \ntop            NaN             NaN            NaN         NaN             NaN   \nfreq           NaN             NaN            NaN         NaN             NaN   \nmean      5.630252       37.269615       2.360084    7.882353      245.781513   \nstd       1.241787        2.971365       0.411393    2.482603       34.765316   \nmin       3.000000       30.480000       1.200000    4.000000      128.000000   \n25%       5.000000       35.560000       2.000000    8.000000      256.000000   \n50%       5.000000       38.100000       2.500000    8.000000      256.000000   \n75%       7.000000       39.624000       2.700000    8.000000      256.000000   \nmax       7.000000       43.942000       2.900000   16.000000      256.000000   \n\n         Weight_kg        Price  \ncount   233.000000   238.000000  \nunique         NaN          NaN  \ntop            NaN          NaN  \nfreq           NaN          NaN  \nmean      1.862232  1462.344538  \nstd       0.494332   574.607699  \nmin       0.810000   527.000000  \n25%       1.440000  1066.500000  \n50%       1.870000  1333.000000  \n75%       2.200000  1777.000000  \nmax       3.600000  3810.000000  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": 35
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code to perform the following actions.\n#1. Create regression plots for the attributes \"CPU_frequency\", \"Screen_Size_inch\" and \"Weight_pounds\" against \"Price\".\n#2. Create box plots for the attributes \"Category\", \"GPU\", \"OS\", \"CPU_core\", \"RAM_GB\" and \"Storage_GB_SSD\" against the attribute \"Price\".\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Use a clean style for plots\nsns.set(style=\"whitegrid\")\n\n# 1) Regression plots: Price vs CPU_frequency, Screen_Size_inch, Weight_pounds\nplt.figure(figsize=(18, 5))\n\nplt.subplot(1, 3, 1)\nsns.regplot(x=\"CPU_frequency\", y=\"Price\", data=df, scatter_kws={\"alpha\": 0.6}, line_kws={\"color\": \"orange\"})\nplt.xlabel(\"CPU_frequency\")\nplt.ylabel(\"Price\")\nplt.title(\"Price vs CPU_frequency\")\n\nplt.subplot(1, 3, 2)\nsns.regplot(x=\"Screen_Size_cm\", y=\"Price\", data=df, scatter_kws={\"alpha\": 0.6})\nplt.xlabel(\"Screen_Size_cm\")\nplt.ylabel(\"Price\")\nplt.title(\"Price vs Screen_Size_cm\")\n\nplt.subplot(1, 3, 3)\nsns.regplot(x=\"Weight_kg\", y=\"Price\", data=df, scatter_kws={\"alpha\": 0.6})\nplt.xlabel(\"Weight_kg\")\nplt.ylabel(\"Price\")\nplt.title(\"Price vs Weight_kg\")\n\nplt.tight_layout()\nplt.savefig(\"regression_plots.png\")\nplt.close()\n\n# 2) Box plots: Price by Category, GPU, OS, CPU_core, RAM_GB, Storage_GB_SSD\nplt.figure(figsize=(12, 18))\ncols = [\"Category\", \"GPU\", \"OS\", \"CPU_core\", \"RAM_GB\", \"Storage_GB_SSD\"]\nfor i, col in enumerate(cols, 1):\n    plt.subplot(3, 2, i)\n    x_vals = df[col].astype(str)\n    sns.boxplot(x=x_vals, y=\"Price\", data=df)\n    plt.xticks(rotation=45)\n    plt.xlabel(col)\n    plt.ylabel(\"Price\")\n    plt.title(f\"Price by {col}\")\n\nplt.tight_layout()\nplt.savefig(\"boxplots_price_by_attrs.png\")\nplt.close()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 36
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code for the following.\n#1. Evaluate the correlation value, pearson coefficient and p-values for all numerical attributes against the target attribute \"Price\".\n#2. Don't include the values evaluated for target variable against itself.\n#3. Print these values as a part of a single dataframe against each individual attribute.\n\nfrom scipy.stats import pearsonr\n\n# Identify numeric columns and exclude the target 'Price'\nnumeric_cols = [col for col in df.select_dtypes(include=[\"number\"]).columns if col != \"Price\"]\n\n# Compute correlation, Pearson coefficient, and p-value for each numeric attribute against Price\nresults = []\nfor col in numeric_cols:\n    subset = df[[col, \"Price\"]].dropna()\n    r_value = subset[col].corr(subset[\"Price\"])  # Pearson correlation coefficient\nr_coef, p_val = pearsonr(subset[col], subset[\"Price\"])  # Pearson r and p-value\nresults.append({\n        \"Attribute\": col,\n        \"Correlation\": r_value,\n        \"Pearson_coefficient\": r_coef,\n        \"p_value\": p_val\n    })\n\n# Present results as a single dataframe\nresults_df = pd.DataFrame(results)\nprint(results_df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "   Attribute  Correlation  Pearson_coefficient   p_value\n0  Weight_kg    -0.050707            -0.050707  0.441094\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 37
    },
    {
      "cell_type": "code",
      "source": "#Write a python code that performs the following actions.\n#1. Group the attributes \"GPU\", \"CPU_core\" and \"Price\", as available in a dataframe df\n#2. Create a pivot table for this group, assuming the target variable to be 'Price' and aggregation function as mean\n#3. Plot a pcolor plot for this pivot table.\n\n# Pivot table: mean Price by GPU (rows) and CPU_core (columns)\npivot_table = df.pivot_table(index='GPU', columns='CPU_core', values='Price', aggfunc='mean')\n# Replace missing values with 0 for visualization\npivot_filled = pivot_table.fillna(0)\n\nplt.figure(figsize=(8, 6))\n# Create a colored grid\nplt.pcolormesh(pivot_filled.values, cmap='viridis', shading='auto')\nplt.colorbar(label='Mean Price')\n\n# Set axis labels and ticks\nplt.xticks(np.arange(pivot_filled.shape[1]) + 0.5, [str(c) for c in pivot_filled.columns], rotation=45, ha='right')\nplt.yticks(np.arange(pivot_filled.shape[0]) + 0.5, [str(r) for r in pivot_filled.index])\nplt.xlabel('CPU_core')\nplt.ylabel('GPU')\nplt.title('Mean Price by GPU and CPU_core')\nplt.tight_layout()\nplt.savefig('price_pcolor_pivot.png')\nplt.close()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 38
    },
    {
      "cell_type": "markdown",
      "source": "## Lab on Generatie AI for model development ##",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code that can perform the following tasks.\n#Read the CSV file, located on a given file path, into a pandas data frame, assuming that the first row of the file can be used as the headers for the data.\n\nimport pandas as pd\n\n# Path to the CSV file\nfile_path = \"dataset.csv\"  # Update this to the actual file location\n\n# Read CSV into a DataFrame, using the first row as headers (default behavior)\ndf = pd.read_csv(file_path)\n\n# df now holds the data with headers from the first row\n# Optional: inspect basic information\nprint(f\"DataFrame shape: {df.shape}\")\nprint(df.head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "DataFrame shape: (238, 13)\n   Unnamed: 0 Manufacturer  Category     Screen  GPU  OS  CPU_core  \\\n0           0         Acer         4  IPS Panel    2   1         5   \n1           1         Dell         3    Full HD    1   1         3   \n2           2         Dell         3    Full HD    1   1         7   \n3           3         Dell         4  IPS Panel    2   1         5   \n4           4           HP         4    Full HD    2   1         7   \n\n   Screen_Size_cm  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_kg  Price  \n0          35.560            1.6       8             256       1.60    978  \n1          39.624            2.0       4             256       2.20    634  \n2          39.624            2.7       8             256       2.20    946  \n3          33.782            1.6       8             128       1.22   1244  \n4          39.624            1.8       8             256       1.91    837  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": 39
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code that performs the following tasks.\n#1. Develops and trains a linear regression model that uses one attribute of a data frame as the source variable and another as a target variable.\n#2. Calculate and display the MSE and R^2 values for the trained model.\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Separate source (X) and target (y) as numpy arrays\nX = df[['CPU_frequency']].to_numpy()  # 2D array required by scikit-learn\ny = df['Price'].to_numpy()\n\n# Initialize and train the linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predict on the training data\ny_pred = model.predict(X)\n\n# Compute evaluation metrics\nmse = mean_squared_error(y, y_pred)\nr2 = r2_score(y, y_pred)\n\n# Display results\nprint(f'MSE: {mse:.6f}')\nprint(f'R^2: {r2:.6f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "MSE: 284583.440587\nR^2: 0.134444\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 40
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code that performs the following tasks.\n#1. Develops and trains a linear regression model that uses some attributes of a data frame as the source variables and one of the attributes as a target variable.\n#2. Calculate and display the MSE and R^2 values for the trained model.\n\n# Select source features and target\nX = df[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD','CPU_core','OS', 'GPU', 'Category' ]].to_numpy()  # 2D array for scikit-learn\ny = df['Price'].to_numpy()\n\n# Initialize and train the linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predict on the training data\ny_pred = model.predict(X)\n\n# Compute evaluation metrics\nmse = mean_squared_error(y, y_pred)\nr2 = r2_score(y, y_pred)\n\n# Display results\nprint(f'MSE: {mse:.6f}')\nprint(f'R^2: {r2:.6f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "MSE: 161680.572639\nR^2: 0.508251\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 41
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code that performs the following tasks.\n#1. Develops and trains multiple polynomial regression models, with orders 2, 3, and 5, that use one attribute of a data frame as the source variable and another as a target variable.\n#2. Calculate and display the MSE and R^2 values for the trained models.\n#3. Compare the performance of the models.\n\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Source feature matrix (n_samples x n_features)\nX = df[['CPU_frequency']].to_numpy()\n# Target vector\ny = df['Price'].to_numpy()\n\n# Polynomial degrees to evaluate\ndegrees = [2, 3, 5]\nresults = {}\n\nfor deg in degrees:\n    # Transform input to polynomial features of the given degree\n    poly = PolynomialFeatures(degree=deg, include_bias=False)\n    X_poly = poly.fit_transform(X)\n    \n    # Train a simple linear regression on the polynomial features\n    model = LinearRegression()\n    model.fit(X_poly, y)\n\n    # Predict on training data\n    y_pred = model.predict(X_poly)\n\n    # Evaluate metrics\n    mse = mean_squared_error(y, y_pred)\n    r2 = r2_score(y, y_pred)\n    results[deg] = {\"mse\": float(mse), \"r2\": float(r2)}\n\n    print(f'Degree {deg}: MSE={mse:.6f}, R^2={r2:.6f}')\n\n# Simple comparisons without using conditional statements\nbest_mse_deg = min(degrees, key=lambda d: results[d][\"mse\"])\nbest_r2_deg = max(degrees, key=lambda d: results[d][\"r2\"])\nprint(f'Best (lowest MSE): degree {best_mse_deg} with MSE {results[best_mse_deg][\"mse\"]:.6f}')\nprint(f'Best (highest R^2): degree {best_r2_deg} with R^2 {results[best_r2_deg][\"r2\"]:.6f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Degree 2: MSE=249022.665968, R^2=0.242601\nDegree 3: MSE=241024.863038, R^2=0.266926\nDegree 5: MSE=229137.295481, R^2=0.303082\nBest (lowest MSE): degree 5 with MSE 229137.295481\nBest (highest R^2): degree 5 with R^2 0.303082\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 42
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code that performs the following tasks.\n#1. Create a pipeline that performs parameter scaling, Polynomial Feature generation, and Linear regression. Use the set of multiple features as before to create this pipeline.\n#2. Calculate and display the MSE and R^2 values for the trained model.\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n# Features and target\nX = df[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD','CPU_core','OS', 'GPU', 'Category']].to_numpy()\ny = df['Price'].to_numpy()\n\n# Create a pipeline: scaling, polynomial features, and linear regression\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n    ('model', LinearRegression())\n])\n\n# Train the model\npipeline.fit(X, y)\n\n# Predict on training data\ny_pred = pipeline.predict(X)\n\n# Evaluate metrics\nmse = mean_squared_error(y, y_pred)\nr2 = r2_score(y, y_pred)\n\n# Display results\nprint(f'MSE: {mse:.6f}')\nprint(f'R^2: {r2:.6f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "MSE: 191186.325630\nR^2: 0.418510\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 43
    },
    {
      "cell_type": "code",
      "source": "#Write a Python code that performs the following tasks.\n#1. Use polynomial features for some of the attributes of a data frame.\n#2. Perform Grid search on a ridge regression model for a set of values of hyperparameter alpha and polynomial features as input.\n#3. Use cross-validation in the Grid search.\n#4. Evaluate the resulting model's MSE and R^2 values.\n\nimport numpy as np\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV, cross_val_predict\n\n# Assume dataset is loaded into a DataFrame named `df` in the environment\n# Use last column as target and remaining numeric features as inputs\ntarget_col = df.columns[-1]\nX = df.drop(columns=[target_col]).select_dtypes(include=[np.number])\ny = df[target_col]\n\n# Define a pipeline with polynomial feature expansion and ridge regression\npipeline = Pipeline([\n    ('poly', PolynomialFeatures()),\n    ('ridge', Ridge())\n])\n\n# Grid search over polynomial degree, inclusion of bias, and ridge alpha with cross-validation\nparam_grid = {\n    'poly__degree': [2, 3],\n    'poly__include_bias': [False],\n    'ridge__alpha': [0.1, 1.0, 10.0]\n}\n\ngrid_search = GridSearchCV(\n    estimator=pipeline,\n    param_grid=param_grid,\n    cv=5,\n    scoring='neg_mean_squared_error',\n    n_jobs=-1\n)\n\ngrid_search.fit(X, y)\n\n# Build a fixed pipeline using the best hyperparameters for final evaluation with CV\nbest_params = grid_search.best_params_\nbest_poly_degree = best_params['poly__degree']\nbest_poly_include_bias = best_params['poly__include_bias']\nbest_alpha = best_params['ridge__alpha']\n\nbest_pipeline = Pipeline([\n    ('poly', PolynomialFeatures(degree=best_poly_degree, include_bias=best_poly_include_bias)),\n    ('ridge', Ridge(alpha=best_alpha))\n])\n\n# Obtain cross-validated predictions using the best pipeline and compute metrics\ny_pred = cross_val_predict(best_pipeline, X, y, cv=5)\n\nmse = mean_squared_error(y, y_pred)\nr2 = r2_score(y, y_pred)\n\nprint(\"Best params:\", grid_search.best_params_)\nprint(\"Cross-validated MSE:\", mse)\nprint(\"Cross-validated R^2:\", r2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Best params: {'poly__degree': 2, 'poly__include_bias': False, 'ridge__alpha': 10.0}\nCross-validated MSE: 0.99814260739466\nCross-validated R^2: -0.05468241983863398\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 46
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "[Abhishek Gagneja](https://www.linkedin.com/in/abhishek-gagneja-23051987/)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-12-10|0.1|Abhishek Gagneja|Initial Draft created|\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Copyright © 2023 IBM Corporation. All rights reserved.\n",
      "metadata": {}
    }
  ]
}